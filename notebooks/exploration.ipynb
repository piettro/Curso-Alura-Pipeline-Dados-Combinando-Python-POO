{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b3c2b4",
   "metadata": {},
   "source": [
    "Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5615f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "path_json = '../data_raw/dados_empresaA.json' \n",
    "path_csv = '../data_raw/dados_empresaB.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba708d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nome do Produto', 'Categoria do Produto', 'Preço do Produto (R$)', 'Quantidade em Estoque', 'Filial']\n",
      "5\n",
      "{'Nome do Produto': 'Blush em pó', 'Categoria do Produto': 'Eletrodomésticos', 'Preço do Produto (R$)': 79.41, 'Quantidade em Estoque': 7, 'Filial': 'Filial 7'}\n",
      "3123\n"
     ]
    }
   ],
   "source": [
    "with open(path_json, 'r') as file:\n",
    "    data_json = json.load(file)\n",
    "\n",
    "columns_names_json = list(data_json[0].keys())\n",
    "\n",
    "print(columns_names_json)\n",
    "print(len(columns_names_json))\n",
    "print(data_json[0])\n",
    "print(len(data_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae8bea31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nome do Produto', 'Categoria do Produto', 'Preço do Produto (R$)', 'Quantidade em Estoque', 'Filial', 'Data da Venda']\n",
      "6\n",
      "{'Nome do Produto': 'LÃ¡pis de sobrancelha', 'Categoria do Produto': 'Roupas', 'Preço do Produto (R$)': '55.17', 'Quantidade em Estoque': '62', 'Filial': 'Filial 1', 'Data da Venda': '2023-04-13 18:58:06.794203'}\n",
      "1323\n"
     ]
    }
   ],
   "source": [
    "data_csv = []\n",
    "with open(path_csv, 'r') as file:\n",
    "    spamreader = csv.DictReader(file, delimiter=',')\n",
    "    for row in spamreader:\n",
    "        data_csv.append(row)\n",
    "\n",
    "key_mapping = {\n",
    "    'Nome do Item':'Nome do Produto', \n",
    "    'ClassificaÃ§Ã£o do Produto':'Categoria do Produto', \n",
    "    'Valor em Reais (R$)':'Preço do Produto (R$)', \n",
    "    'Quantidade em Estoque':'Quantidade em Estoque', \n",
    "    'Nome da Loja':'Filial',\n",
    "    'Data da Venda': 'Data da Venda'\n",
    "}\n",
    "\n",
    "new_data_csv = []\n",
    "\n",
    "for old_dict in data_csv:\n",
    "    dict_temp = {}\n",
    "    for old_key, value in old_dict.items():\n",
    "        dict_temp[key_mapping[old_key]] = value\n",
    "\n",
    "    new_data_csv.append(dict_temp)\n",
    "\n",
    "columns_names_csv = list(new_data_csv[0].keys())\n",
    "\n",
    "print(columns_names_csv)\n",
    "print(len(columns_names_csv))\n",
    "print(new_data_csv[0])\n",
    "print(len(new_data_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e326ede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4446\n"
     ]
    }
   ],
   "source": [
    "combined_list = []\n",
    "\n",
    "combined_list.extend(data_json)\n",
    "combined_list.extend(new_data_csv)\n",
    "columns_names_combined_list = list(combined_list[-1].keys())\n",
    "\n",
    "print(len(combined_list))\n",
    "\n",
    "path_combined_data = '../data_processed/combined_data.csv'\n",
    "\n",
    "with open(path_combined_data, 'w') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=columns_names_combined_list)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in combined_list:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aef7b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_table = [columns_names_combined_list]\n",
    "\n",
    "for row in combined_list:\n",
    "    new_row = []\n",
    "    for column in columns_names_combined_list:\n",
    "        new_row.append(row.get(column, 'Unavailable'))\n",
    "\n",
    "    combined_data_table.append(new_row)\n",
    "\n",
    "path_combined_data = '../data_processed/combined_data.csv'\n",
    "\n",
    "with open(path_combined_data, 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(combined_data_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
